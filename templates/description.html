<!DOCTYPE html>
<html>
<style>
table, th, td {
  border:1px solid black;
}
</style>
<body>

<H4>Introduction</H4>
<p>Thanks all for your interests for our challenge! We decided to extend the submission timeline. Please take a look at the updated timeline.</p>

<p>An excellent shopping assistant in bricks and mortar stores can bring a personal, professional and warm service to the customer.  One important customer service the shopping assistant can offer is to recommend new product based on the intent of the customer (described by natural language) and previously recommended products. For example, after trying on one dress, the customer may ask for a new dress with longer sleeves. The shopping assistant should be able to take the feedback and recommend a new dress.</p>

<img src="https://drive.google.com/uc?export=view&id=1oeGQeBeU4aD5VPPmvIEa_8JUfqZNA-qB" width="600px"
  height="220px"/>

<p>The Amazon Alexa Language-Assisted Product Search challenge aims at bringing similar experience to online shopping.  The challenge is part of the <a href="https://ilr-workshop.github.io/ECCVW2022/">Instance-Level Recognition workshop</a>. We are focusing on “one-shot product search with language feedback” problem. Given a query product/image as well as some natural language feedbacks from the customer, the goal of the challenge is to find a product which is similar to the query product and fulfills the feedback given by the customer. </p>

<H4>Dataset</H4>

<p>The dataset contains 3 splits: training, development and evaluation. The annotation can be downloaded from <a href="https://www.amazon.com/clouddrive/share/1kY62fIYfCWcYYve9EY6ANolZ0BWdJXHiMGqJt0ZVgi">Amazon Drive</a>. Meanwhile, the code used for downloading and visualizing the data can be found <a href="https://github.com/amazon-science/amazon-alexa-language-assisted-product-search">here</a>.</p>

<H5>Training Split</H5>
<p>The training split contains 2 files:  
<br><br>
<i>1. <a href="https://www.amazon.com/clouddrive/share/jJxbtRqih3ScOWGqWJifEemVAqS4R5WzuDey7dcMiuo">The feedback annotation file</a> </i>
<br>
The file contains the source product, target product, non-target product and 3 different language feedbacks provided by the annotator when they wanted to buy the <i>Target Product</i> (not the <i>Non-Target Product</i>) after showing the <i>Source Product</i>. For each product, we will provide one ASIN (Product ID) and one product image ID. One product may have multiple product images. The image ID we shown in the csv file is the one we showed to the annotator. All products are from the apparel category, including but not limited to clothing, backpack, handbag and sun-glasses. 
<table>
  <tr>
    <th>Source ASIN</th>
    <th>Source Image ID</th>
    <th>Target ASIN</th>
    <th>Target Image ID</th>
    <th>Non-Target ASIN</th>
    <th>Non-Target Image ID</th>
    <th>Feedback 1</th>
    <th>Feedback 2</th>
    <th>Feedback 3</th>
  </tr>
  <tr>
    <th>B07QW6ZDJZ</th>
    <th>31DIXIgC5wL</th>
    <th>B07K8ZT1FW</th>
    <th>31vP-SHrTQL</th>
    <th>B0835P5MFF</th>
    <th>316vY0N-uJL</th>
    <th>with a grey dress pant</th>
    <th>with side button placket waistband</th>
    <th>with a taper leg</th>
  </tr>
</table>

<p><b>Specific product images linked in the dataset may be removed from Amazon's servers from time to time and become unavailable.</b></p>

<i>2. <a href="https://www.amazon.com/clouddrive/share/O9PxFuKZ1x1qmbKhFDtmmqTgXUWORtBN8JXELTaIqYb">The gallery image file</a> </i>
<br>
The gallery image file is a csv file. Each line contains the ASIN and the Image ID for a product image. The gallery dataset is for the participants to do pretraining or test the model performance on large-scale dataset. Products are <b>not</b> limited to apparel category.<table>
  <tr>
    <th>ASIN</th>
    <th>Image ID</th>
  </tr>
  <tr>
    <th>B076XHGMDF</th>
    <th>51vqFfngUiL</th>
  </tr>
</table>
</p>

<H5> Development Split</H5>
<p>The development split contains 1 query file:
<br><br>
<i>1. <a href="https://www.amazon.com/clouddrive/share/3yATTzqkDv1pBlDNVTyeeVDuhRhgvbfyUEySdrYOHDC">The query file</a> </i>
<br>
The query file is a jsonl file. Each line contains one query (a product and all three feedbacks from the annotator), and a set of candidate products. All candidate products are from the apparel category as well. 
<pre>
<code>
{<br>
&emsp;"index": 1,<br>
&emsp;"source_pid": "31DIXIgC5wL",<br>
&emsp;"feedback1": "with a grey dress pant",<br>
&emsp;"feedback2": "with side button placket waistband",<br>
&emsp;"feedback3": "with a taper leg",<br>
&emsp;"candidates": [<br>
&emsp;&emsp;{"candidate_pid": "71sq8PHKCeL"},<br>
&emsp;&emsp;{"candidate_pid": "41qOjyIs8YL"}<br>
&emsp;]<br>
}
</code>
</pre>

<H5> Evaluation Split</H5>
<p><b>If you download the file before 3/9, please update to the new version.</b><br>
The evaluation split contains 1 gallery file and 1 query file. To download the file, you need to first install aws cli 
<pre>
<code>
pip install awscli
</code>
</pre>
Configure the cli by running
<pre>
<code>
aws configure
</code>
</pre>
Use <i>AKIARCACTE5G7WI4CVMK</i> as the access key and <i>x8bsqxhZbixWeVUbLvxpmWFY6AjfFwZEDrpsIovp</i> as the secret key. Keep region and output format as default (You can use your own aws configure as well).

<br><br>
<i>1. The gallery image file</i>
<br>
The gallery image file is a csv file. It only contains the Image ID. The products are different in training and evaluation splits. 
<table>
  <tr>
    <th>Image ID</th>
  </tr>
  <tr>
    <th>51vqFfngUiL</th>
  </tr>
</table>
To download the evaluation gallery file,
<pre>
<code>
aws s3 cp s3://amazon-alexa-language-assisted-product-search-dataset-2022/\<br>
amazon-alexa-language-assisted-product-search-dataset-2022/evaluation/cleaned_eval_gallery_file_cleaned_200k_v2.csv {your_output_path}
</code>
</pre>

<i>2. Query file</i>
<br>
The format is similar to the query file in the development split, however, the candidate list is not given. Also, to test the out-of-domain performance of the model, besides products from the apparel category, there are some queries from the furniture categoryas well.
<pre>
<code>
{<br>
&emsp;"index": 1,<br>
&emsp;"source_pid": "31DIXIgC5wL",<br>
&emsp;"feedback1": "with a grey dress pant",<br>
&emsp;"feedback2": "with side button placket waistband",<br>
&emsp;"feedback3": "with a taper leg",<br>
}
</code>
</pre>
To download the query file,
<pre>
<code>
aws s3 cp s3://amazon-alexa-language-assisted-product-search-dataset-2022/\<br>
amazon-alexa-language-assisted-product-search-dataset-2022/evaluation/evaluation_query_file_v2.jsonl {your_output_path}
</code>
</pre>
</p>

<H4>License</H4>
<p>The dataset (all the annotations) is released under <a href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a> license.</p>

<H4>Timeline</H4>
<ul>
  <li>09/23/2022: Training Data Release</li>
  <li>10/12/2022: Development Data Release</li>
  <li>12/02/2022: Baseline Checkpoint Release</li>
  <li>12/10/2022: Baseline Training Code Release</li>
  <li>02/06/2023: Evaluation Data Release</li>
  <li>03/06/2023: Evaluation Submission Open</li>
  <li>03/31/2023: Evaluation Result Submission Deadline</li>
  <li>04/10/2023: Evaluation Result Release</li>
</ul>

<H4>Organizers</H4>
<p>
Xu Zhang (xzhnamz@amazon.com) <br>
Sanqiang Zhao (sanqiang@amazon.com) <br>
Skyler Zheng (nzhengji@amazon.com) <br>
Anwesan Pal (a2pal@eng.ucsd.edu) <br>
Yue Wu (wuayue@amazon.com) <br>
Prateek Singhal (prtksngh@amazon.com) <br>
Robinson Piramuthu (robinpir@amazon.com) <br>
Pradeep Natarajan (natarap@amazon.com) <br>
</p>
</body>
</html>
